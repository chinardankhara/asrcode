{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from analysis import calculate_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get transcriptions over the directory\n",
    "\n",
    "# os.chdir('./dev-other')   \n",
    "# for filename in os.listdir():\n",
    "#     #if not DS_Store, go into the directory\n",
    "#     if filename != '.DS_Store':\n",
    "#         os.chdir(filename)\n",
    "#         for file in os.listdir():\n",
    "#             if file != '.DS_Store':\n",
    "#                 os.chdir(file)\n",
    "#                 for file in os.listdir():\n",
    "#                     #if filename ends with flac, run the function\n",
    "#                     if file.endswith('.flac'):\n",
    "#                         get_assembly(file)\n",
    "#                         get_openai(file)\n",
    "#                         get_azure(file)\n",
    "#                         await get_deepgram(file)\n",
    "#                 os.chdir('..')\n",
    "#         os.chdir('..')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data collection storage\n",
    "\n",
    "openai_wer_list = []\n",
    "azure_wer_list = []\n",
    "assembly_wer_list = []\n",
    "deepgram_wer_list = []\n",
    "\n",
    "openai_levenshtein_list = []\n",
    "azure_levenshtein_list = []\n",
    "assembly_levenshtein_list = []\n",
    "deepgram_levenshtein_list = []\n",
    "\n",
    "openai_response_time_list = []\n",
    "azure_response_time_list = []\n",
    "assembly_response_time_list = []\n",
    "deepgram_response_time_list = []\n",
    "\n",
    "openai_rtf_list = []\n",
    "azure_rtf_list = []\n",
    "assembly_rtf_list = []\n",
    "deepgram_rtf_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1255\n",
      "1630\n",
      "700\n",
      "1585\n",
      "3660\n",
      "116\n",
      "1650\n",
      "1651\n",
      "2506\n",
      "3663\n",
      "1701\n",
      "1686\n"
     ]
    }
   ],
   "source": [
    "os.chdir('./dev-other')\n",
    "\n",
    "for filename in os.listdir():\n",
    "    #if not DS_Store, go into the directory\n",
    "    if filename != '.DS_Store':\n",
    "        os.chdir(filename)\n",
    "        for file in os.listdir():\n",
    "            if file != '.DS_Store':\n",
    "                os.chdir(file)\n",
    "                for file2 in os.listdir():\n",
    "                    if 'trans' in file2:\n",
    "                        ref_file = file2\n",
    "                    elif 'openai' in file2:\n",
    "                        openai_file = file2\n",
    "                    elif 'azure' in file2:\n",
    "                        azure_file = file2\n",
    "                    elif 'assembly' in file2:\n",
    "                        assembly_file = file2\n",
    "                    elif 'deepgram' in file2:\n",
    "                        deepgram_file = file2\n",
    "                #extend each list with the list returned from the function\n",
    "                temp = calculate_metrics(ref_file, openai_file)\n",
    "                openai_wer_list.extend(temp[0])\n",
    "                openai_levenshtein_list.extend(temp[1])\n",
    "                openai_response_time_list.extend(temp[2])\n",
    "                openai_rtf_list.extend(temp[3])\n",
    "\n",
    "                temp = calculate_metrics(ref_file, azure_file)\n",
    "                azure_wer_list.extend(temp[0])\n",
    "                azure_levenshtein_list.extend(temp[1])\n",
    "                azure_response_time_list.extend(temp[2])\n",
    "                azure_rtf_list.extend(temp[3])\n",
    "\n",
    "                temp = calculate_metrics(ref_file, assembly_file)\n",
    "                assembly_wer_list.extend(temp[0])\n",
    "                assembly_levenshtein_list.extend(temp[1])\n",
    "                assembly_response_time_list.extend(temp[2])\n",
    "                assembly_rtf_list.extend(temp[3])\n",
    "\n",
    "                temp = calculate_metrics(ref_file, deepgram_file)\n",
    "                deepgram_wer_list.extend(temp[0])\n",
    "                deepgram_levenshtein_list.extend(temp[1])\n",
    "                deepgram_response_time_list.extend(temp[2])\n",
    "                deepgram_rtf_list.extend(temp[3])\n",
    "                os.chdir('..')\n",
    "        os.chdir('..')\n",
    "        print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('./dev-other/1255/138279/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from analysis import wer, levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_wer = []\n",
    "temp_levenshtein = []\n",
    "temp_response_time = []\n",
    "temp_rtf = []\n",
    "\n",
    "with open('1255-138279.trans.txt') as f:\n",
    "    ref = f.read().split('\\n')\n",
    "    ref.remove('')\n",
    "        #convert ref to dictionary\n",
    "    ref = [i.split(' ') for i in ref]\n",
    "    ref = {i[0].strip(): ' '.join(i[1:]) for i in ref}\n",
    "    \n",
    "with open('1255-138279-openai.txt') as f:\n",
    "    hyp = f.read().split('\\n')\n",
    "    hyp.remove('')\n",
    "    hyp = [i.split(',') for i in hyp]\n",
    "    hyp = {i[0].strip(): i[1:] for i in hyp}\n",
    "\n",
    "for i in ref:\n",
    "    temp_wer.append(wer(ref[i], hyp[i][0]))\n",
    "    temp_levenshtein.append(levenshtein(ref[i], hyp[i][0]))\n",
    "    temp_response_time.append(float(hyp[i][1].strip()))\n",
    "    temp_rtf.append(float(hyp[i][2].strip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {'openai_wer': openai_wer_list, 'azure_wer': azure_wer_list, 'assembly_wer': assembly_wer_list, 'deepgram_wer': deepgram_wer_list,\n",
    "             'openai_levenshtein': openai_levenshtein_list, 'azure_levenshtein': azure_levenshtein_list, 'assembly_levenshtein': assembly_levenshtein_list, 'deepgram_levenshtein': deepgram_levenshtein_list,\n",
    "             'openai_response_time': openai_response_time_list, 'azure_response_time': azure_response_time_list, 'assembly_response_time': assembly_response_time_list, 'deepgram_response_time': deepgram_response_time_list,\n",
    "             'openai_rtf': openai_rtf_list, 'azure_rtf': azure_rtf_list, 'assembly_rtf': assembly_rtf_list, 'deepgram_rtf': deepgram_rtf_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('data_dict.pickle', 'wb') as handle:\n",
    "    pickle.dump(data_dict, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data_dict.pickle', 'rb') as handle:\n",
    "    data_dict = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['openai_wer', 'azure_wer', 'assembly_wer', 'deepgram_wer', 'openai_levenshtein', 'azure_levenshtein', 'assembly_levenshtein', 'deepgram_levenshtein', 'openai_response_time', 'azure_response_time', 'assembly_response_time', 'deepgram_response_time', 'openai_rtf', 'azure_rtf', 'assembly_rtf', 'deepgram_rtf'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
